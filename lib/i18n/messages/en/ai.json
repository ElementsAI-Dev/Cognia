{
  "aiSettings": {
    "title": "AI Message Settings",
    "description": "Configure AI generation parameters for this conversation",
    "temperature": "Temperature",
    "temperatureDesc": "Controls randomness. Lower values are more focused, higher values are more creative.",
    "precise": "Precise",
    "balanced": "Balanced",
    "creative": "Creative",
    "maxTokens": "Max Tokens",
    "maxTokensDesc": "Maximum number of tokens in the response.",
    "topP": "Top P (Nucleus Sampling)",
    "topPTooltip": "Nucleus sampling parameter",
    "topPDesc": "Alternative to temperature. Consider tokens with top_p probability mass.",
    "frequencyPenalty": "Frequency Penalty",
    "frequencyPenaltyDesc": "Reduces repetition by penalizing tokens based on frequency. Positive values decrease repetition.",
    "presencePenalty": "Presence Penalty",
    "presencePenaltyDesc": "Encourages new topics by penalizing tokens that have appeared. Positive values increase diversity.",
    "resetDefaults": "Reset to Defaults",
    "done": "Done"
  },
  "modelPicker": {
    "title": "Select Model",
    "searchPlaceholder": "Search models...",
    "all": "All",
    "flagship": "Flagship",
    "aggregator": "Aggregator",
    "fast": "Fast",
    "local": "Local",
    "flagshipDesc": "OpenAI, Anthropic, Google, xAI",
    "aggregatorDesc": "OpenRouter, Together AI",
    "fastDesc": "Groq, Cerebras, DeepSeek",
    "localDesc": "Ollama",
    "recentModels": "Recent Models",
    "allModels": "All Models",
    "noModels": "No models available",
    "configureProviders": "Configure providers in settings",
    "showOnlyEnabled": "Show only enabled",
    "vision": "Vision",
    "tools": "Tools"
  },
  "providers": {
    "title": "AI Providers",
    "apiKey": "API Key",
    "apiKeyPlaceholder": "Enter your API key",
    "baseUrl": "Base URL",
    "test": "Test",
    "testing": "Testing...",
    "testConnection": "Test Connection",
    "connectionSuccess": "Connection successful",
    "connectionFailed": "Connection failed",
    "enabled": "Enabled",
    "disabled": "Disabled",
    "availableModels": "Available Models",
    "getApiKey": "Get your API key from",
    "dashboard": "Dashboard",
    "localProvider": "Local",
    "local": "Local",
    "customProviders": "Custom Providers",
    "addCustomProvider": "Add Custom Provider",
    "addProvider": "Add Provider",
    "providerName": "Provider Name",
    "models": "Models",
    "modelsCount": "models",
    "modelsPlaceholder": "Enter model names (comma-separated)",
    "securityTitle": "Security Notice",
    "securityDescription": "Your API keys are stored locally in your browser and never sent to our servers.",
    "ollamaURL": "Ollama URL",
    "ollamaHint": "Make sure Ollama is running locally.",
    "openaiCompatible": "OpenAI Compatible",
    "customProvidersDescription": "Add custom OpenAI-compatible API providers.",
    "customProviderDescription": "Configure a custom OpenAI-compatible API provider.",
    "editCustomProvider": "Edit Custom Provider",
    "providerNamePlaceholder": "My Provider",
    "baseURL": "Base URL",
    "baseURLHint": "Use a proxy URL or self-hosted endpoint. Leave empty for default.",
    "customBaseURL": "Custom Base URL",
    "baseURLPlaceholder": "https://api.example.com/v1",
    "modelPlaceholder": "Enter model name",
    "modelsHint": "Click on a model to set it as default. Click the X to remove.",
    "default": "default",
    "confirmDeleteProvider": "Delete this provider?",
    "testAllProviders": "Test All Providers",
    "testResults": "Test Results",
    "passed": "passed",
    "failed": "failed",
    "providersConfigured": "providers configured",
    "clickToSetDefault": "Click to set default",
    "openai": "OpenAI",
    "openaiDescription": "GPT-4o, GPT-4 Turbo, and more",
    "anthropic": "Anthropic",
    "anthropicDescription": "Claude 4 Sonnet, Claude 4 Opus",
    "google": "Google AI",
    "googleDescription": "Gemini 2.0 Flash, Gemini 1.5 Pro",
    "deepseek": "DeepSeek",
    "deepseekDescription": "DeepSeek Chat, DeepSeek Reasoner",
    "groq": "Groq",
    "groqDescription": "Ultra-fast inference with Llama 3.3",
    "mistral": "Mistral AI",
    "mistralDescription": "Mistral Large, Mistral Small",
    "ollama": "Ollama (Local)",
    "ollamaDescription": "Run models locally with Ollama",
    "ollamaUrlPlaceholder": "http://localhost:11434",
    "ollamaConnected": "Connected",
    "ollamaDisconnected": "Not connected",
    "ollamaModels": "Local Models",
    "ollamaInstalledModels": "Installed Models",
    "ollamaNoModels": "No models installed. Pull a model to get started.",
    "ollamaNotRunning": "Ollama is not running",
    "ollamaStartHint": "Start Ollama with",
    "ollamaPullPlaceholder": "Enter model name (e.g., llama3.2, qwen2.5)",
    "ollamaPopularModels": "Popular Models",
    "ollamaDeleteTitle": "Delete Model",
    "ollamaDeleteDescription": "Are you sure you want to delete {model}? This action cannot be undone.",
    "localProvidersTitle": "Local Providers",
    "localProvidersDescription": "Run AI models locally on your machine",
    "lmstudio": "LM Studio",
    "lmstudioDescription": "Desktop app for running local LLMs",
    "llamacpp": "llama.cpp Server",
    "llamacppDescription": "High-performance C++ inference server",
    "llamafile": "llamafile",
    "llamafileDescription": "Single-file executable LLM server",
    "vllm": "vLLM",
    "vllmDescription": "High-throughput GPU inference engine",
    "localai": "LocalAI",
    "localaiDescription": "Self-hosted OpenAI alternative",
    "jan": "Jan",
    "janDescription": "Open-source ChatGPT alternative",
    "textgenwebui": "Text Generation WebUI",
    "textgenwebuiDescription": "Gradio web UI with OpenAI API",
    "koboldcpp": "KoboldCpp",
    "koboldcppDescription": "Easy-to-use llama.cpp fork",
    "tabbyapi": "TabbyAPI",
    "tabbyapiDescription": "Exllamav2 API server",
    "oauthLogin": "Quick Login",
    "oauthConnected": "Connected",
    "oauthDisconnectHint": "Click to disconnect OAuth",
    "oauthLoginHint": "Login with {provider} to get API key automatically",
    "oauthNoCode": "No authorization code received",
    "export": "Export",
    "import": "Import",
    "exportTitle": "Export Provider Settings",
    "exportDescription": "Export your provider configurations to a JSON file",
    "exportWarning": "API keys will be included only if you check the option below. Handle with care.",
    "includeApiKeys": "Include API keys (not recommended for sharing)",
    "exportNow": "Export",
    "importTitle": "Import Provider Settings",
    "importFrom": "Exported on {date}",
    "importSuccess": "Settings imported successfully!",
    "importProviderCount": "{count} provider settings",
    "importCustomCount": "{count} custom providers",
    "importNow": "Import",
    "cancel": "Cancel",
    "healthStatus": "Health Status",
    "latency": "Latency",
    "quotaUsage": "Quota Usage",
    "rateLimitRemaining": "Rate Limit",
    "requests": "requests",
    "neverChecked": "Never checked",
    "justNow": "Just now",
    "minutesAgo": "{count}m ago",
    "hoursAgo": "{count}h ago",
    "status": {
      "healthy": "Healthy",
      "degraded": "Degraded",
      "error": "Error",
      "unknown": "Unknown"
    },
    "xai": "xAI (Grok)",
    "xaiDescription": "Grok 3, Grok 3 Mini",
    "togetherai": "Together AI",
    "togetheraiDescription": "Fast inference for open source models",
    "openrouter": "OpenRouter",
    "openrouterDescription": "Access 200+ models with OAuth login",
    "cohere": "Cohere",
    "cohereDescription": "Command R+, enterprise RAG",
    "fireworks": "Fireworks AI",
    "fireworksDescription": "Ultra-fast compound AI",
    "cerebras": "Cerebras",
    "cerebrasDescription": "Fastest inference with custom AI chips",
    "sambanova": "SambaNova",
    "sambanovaDescription": "Enterprise AI with free tier",
    "connected": "Connected",
    "disconnected": "Disconnected"
  },
  "reasoning": {
    "thinking": "Thinking...",
    "thoughtFewSeconds": "Thought for a few seconds",
    "thoughtSeconds": "Thought for {duration} seconds"
  },
  "chainOfThought": {
    "title": "Chain of Thought"
  }
}