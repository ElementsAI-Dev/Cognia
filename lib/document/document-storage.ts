/**
 * Document Storage - Integration layer between document processing and database
 * Handles storing processed documents with optional embedding generation
 */

import { documentRepository, type CreateDocumentInput, type UpdateDocumentInput } from '@/lib/db/repositories/document-repository';
import { processDocument, processDocumentAsync, type ProcessedDocument, type ProcessingOptions } from './document-processor';
import type { StoredDocument, DocumentFilter, DocumentType } from '@/types/document';

export interface StoreDocumentOptions extends ProcessingOptions {
  projectId?: string;
  collectionId?: string;
  generateEmbedding?: boolean;
  embeddingConfig?: {
    provider: 'openai' | 'google';
    model: string;
    apiKey: string;
  };
}

export interface StoreDocumentResult {
  document: StoredDocument;
  processed: ProcessedDocument;
  embeddingGenerated: boolean;
}

export interface BatchStoreProgress {
  total: number;
  processed: number;
  succeeded: number;
  failed: number;
  currentFile?: string;
}

export interface BatchStoreOptions extends StoreDocumentOptions {
  onProgress?: (progress: BatchStoreProgress) => void;
  continueOnError?: boolean;
}

/**
 * Store a text-based document (sync processing)
 */
export async function storeDocument(
  filename: string,
  content: string,
  options: StoreDocumentOptions = {}
): Promise<StoreDocumentResult> {
  // Process the document
  const processed = processDocument(
    '', // ID will be generated by repository
    filename,
    content,
    {
      extractEmbeddable: options.extractEmbeddable ?? true,
      generateChunks: options.generateChunks,
      chunkingOptions: options.chunkingOptions,
    }
  );

  // Prepare for storage
  const createInput: CreateDocumentInput = {
    filename: processed.filename,
    type: processed.type,
    content: processed.content,
    embeddableContent: processed.embeddableContent,
    metadata: processed.metadata,
    projectId: options.projectId,
    collectionId: options.collectionId,
  };

  // Generate embedding if requested
  let embeddingGenerated = false;
  if (options.generateEmbedding && options.embeddingConfig) {
    try {
      const embedding = await generateDocumentEmbedding(
        processed.embeddableContent,
        options.embeddingConfig
      );
      createInput.embedding = embedding;
      embeddingGenerated = true;
    } catch (error) {
      console.warn('Failed to generate embedding:', error);
    }
  }

  // Store in database
  const document = await documentRepository.create(createInput);

  return {
    document,
    processed: { ...processed, id: document.id },
    embeddingGenerated,
  };
}

/**
 * Store a binary document (async processing for PDF, Word, Excel, etc.)
 */
export async function storeDocumentAsync(
  filename: string,
  data: string | ArrayBuffer,
  options: StoreDocumentOptions = {}
): Promise<StoreDocumentResult> {
  // Process the document asynchronously
  const processed = await processDocumentAsync(
    '', // ID will be generated by repository
    filename,
    data,
    {
      extractEmbeddable: options.extractEmbeddable ?? true,
      generateChunks: options.generateChunks,
      chunkingOptions: options.chunkingOptions,
    }
  );

  // Prepare for storage
  const createInput: CreateDocumentInput = {
    filename: processed.filename,
    type: processed.type,
    content: processed.content,
    embeddableContent: processed.embeddableContent,
    metadata: processed.metadata,
    projectId: options.projectId,
    collectionId: options.collectionId,
  };

  // Generate embedding if requested
  let embeddingGenerated = false;
  if (options.generateEmbedding && options.embeddingConfig) {
    try {
      const embedding = await generateDocumentEmbedding(
        processed.embeddableContent,
        options.embeddingConfig
      );
      createInput.embedding = embedding;
      embeddingGenerated = true;
    } catch (error) {
      console.warn('Failed to generate embedding:', error);
    }
  }

  // Store in database
  const document = await documentRepository.create(createInput);

  return {
    document,
    processed: { ...processed, id: document.id },
    embeddingGenerated,
  };
}

/**
 * Store multiple documents with progress tracking
 */
export async function storeDocuments(
  files: { filename: string; content: string }[],
  options: BatchStoreOptions = {}
): Promise<StoreDocumentResult[]> {
  const results: StoreDocumentResult[] = [];
  const { onProgress, continueOnError = true } = options;

  const progress: BatchStoreProgress = {
    total: files.length,
    processed: 0,
    succeeded: 0,
    failed: 0,
  };

  for (const file of files) {
    progress.currentFile = file.filename;
    onProgress?.(progress);

    try {
      const result = await storeDocument(file.filename, file.content, options);
      results.push(result);
      progress.succeeded++;
    } catch (error) {
      console.error(`Failed to store ${file.filename}:`, error);
      progress.failed++;
      if (!continueOnError) {
        break;
      }
    }

    progress.processed++;
    onProgress?.(progress);
  }

  return results;
}

/**
 * Update a stored document
 */
export async function updateStoredDocument(
  id: string,
  content: string,
  options: StoreDocumentOptions = {}
): Promise<StoredDocument | undefined> {
  const existing = await documentRepository.getById(id);
  if (!existing) return undefined;

  // Re-process content
  const processed = processDocument(
    id,
    existing.filename,
    content,
    {
      extractEmbeddable: options.extractEmbeddable ?? true,
      generateChunks: options.generateChunks,
      chunkingOptions: options.chunkingOptions,
    }
  );

  const updates: UpdateDocumentInput = {
    content: processed.content,
    embeddableContent: processed.embeddableContent,
    metadata: processed.metadata,
  };

  // Regenerate embedding if requested
  if (options.generateEmbedding && options.embeddingConfig) {
    try {
      const embedding = await generateDocumentEmbedding(
        processed.embeddableContent,
        options.embeddingConfig
      );
      updates.embedding = embedding;
      updates.isIndexed = true;
    } catch (error) {
      console.warn('Failed to generate embedding:', error);
    }
  }

  return documentRepository.update(id, updates);
}

/**
 * Get documents with optional filtering
 */
export async function getStoredDocuments(
  filter?: DocumentFilter
): Promise<StoredDocument[]> {
  if (filter) {
    return documentRepository.filter(filter);
  }
  return documentRepository.getAll();
}

/**
 * Get a single stored document
 */
export async function getStoredDocument(
  id: string
): Promise<StoredDocument | undefined> {
  return documentRepository.getById(id);
}

/**
 * Delete a stored document
 */
export async function deleteStoredDocument(id: string): Promise<void> {
  return documentRepository.delete(id);
}

/**
 * Search documents by content
 */
export async function searchDocuments(
  query: string,
  options: {
    limit?: number;
    projectId?: string;
    type?: DocumentType;
  } = {}
): Promise<StoredDocument[]> {
  const { limit = 10, projectId, type } = options;

  // First try content search
  let results = await documentRepository.searchByContent(query, limit * 2);

  // Apply filters
  if (projectId) {
    results = results.filter((doc) => doc.projectId === projectId);
  }
  if (type) {
    results = results.filter((doc) => doc.type === type);
  }

  return results.slice(0, limit);
}

/**
 * Generate embedding for document content
 */
async function generateDocumentEmbedding(
  content: string,
  config: {
    provider: 'openai' | 'google';
    model: string;
    apiKey: string;
  }
): Promise<number[]> {
  const { generateEmbedding } = await import('@/lib/vector/embedding');
  
  const result = await generateEmbedding(
    content,
    {
      provider: config.provider,
      model: config.model,
    },
    config.apiKey
  );

  return result.embedding;
}

/**
 * Index unindexed documents with embeddings
 */
export async function indexUnindexedDocuments(
  embeddingConfig: {
    provider: 'openai' | 'google';
    model: string;
    apiKey: string;
  },
  options: {
    batchSize?: number;
    onProgress?: (indexed: number, total: number) => void;
  } = {}
): Promise<number> {
  const { batchSize = 10, onProgress } = options;
  const unindexed = await documentRepository.getUnindexed();
  
  let indexed = 0;
  const total = unindexed.length;

  for (let i = 0; i < unindexed.length; i += batchSize) {
    const batch = unindexed.slice(i, i + batchSize);

    for (const doc of batch) {
      try {
        const content = doc.embeddableContent || doc.content;
        const embedding = await generateDocumentEmbedding(content, embeddingConfig);
        await documentRepository.updateEmbedding(doc.id, embedding);
        indexed++;
      } catch (error) {
        console.warn(`Failed to index document ${doc.id}:`, error);
      }
    }

    onProgress?.(indexed, total);
  }

  return indexed;
}

/**
 * Perform vector similarity search on indexed documents
 */
export async function vectorSearchDocuments(
  query: string,
  embeddingConfig: {
    provider: 'openai' | 'google';
    model: string;
    apiKey: string;
  },
  options: {
    topK?: number;
    threshold?: number;
    projectId?: string;
  } = {}
): Promise<{ document: StoredDocument; similarity: number }[]> {
  const { topK = 5, threshold = 0.5, projectId } = options;

  // Get query embedding
  const queryEmbedding = await generateDocumentEmbedding(query, embeddingConfig);

  // Get documents with embeddings
  let docsWithEmbeddings = await documentRepository.getWithEmbeddings();

  // Filter by project if specified
  if (projectId) {
    const projectDocs = await documentRepository.getByProjectId(projectId);
    const projectDocIds = new Set(projectDocs.map((d) => d.id));
    docsWithEmbeddings = docsWithEmbeddings.filter((d) => projectDocIds.has(d.id));
  }

  // Calculate similarities
  const { findMostSimilar } = await import('@/lib/vector/embedding');
  
  const similar = findMostSimilar(
    queryEmbedding,
    docsWithEmbeddings,
    topK,
    threshold
  );

  // Fetch full documents
  const results: { document: StoredDocument; similarity: number }[] = [];
  for (const item of similar) {
    const doc = await documentRepository.getById(item.id);
    if (doc) {
      results.push({ document: doc, similarity: item.similarity });
    }
  }

  return results;
}

/**
 * Get storage statistics
 */
export async function getStorageStats(): Promise<{
  totalDocuments: number;
  indexedDocuments: number;
  unindexedDocuments: number;
  byType: Record<string, number>;
  totalSize: number;
}> {
  const all = await documentRepository.getAll();
  const indexed = all.filter((d) => d.isIndexed);
  
  const byType: Record<string, number> = {};
  let totalSize = 0;

  for (const doc of all) {
    byType[doc.type] = (byType[doc.type] || 0) + 1;
    totalSize += doc.metadata.size || 0;
  }

  return {
    totalDocuments: all.length,
    indexedDocuments: indexed.length,
    unindexedDocuments: all.length - indexed.length,
    byType,
    totalSize,
  };
}
