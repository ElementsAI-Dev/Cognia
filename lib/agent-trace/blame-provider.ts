/**
 * AI Blame Provider â€” Line-level code attribution system.
 *
 * Combines agent trace data with VCS (git) blame to determine
 * whether each line of a file was written by AI or a human.
 * Inspired by Cursor Blame (Enterprise feature in Cursor 2.4).
 *
 * Attribution types:
 * - ai: Code generated by an AI agent (with model attribution)
 * - human: Code written directly by a developer
 * - mixed: Human-edited AI output or AI-edited human code
 * - unknown: Origin cannot be determined
 */

import { agentTraceRepository } from '@/lib/db/repositories/agent-trace-repository';
import type { AgentTraceRecord, TraceRange, ContributorType } from '@/types/agent-trace';

/**
 * Attribution info for a single line.
 */
export interface BlameLineInfo {
  lineNumber: number;
  attribution: ContributorType;
  modelId?: string;
  toolName?: string;
  sessionId?: string;
  conversationUrl?: string;
  timestamp?: string;
  confidence: number;
}

/**
 * File-level blame statistics.
 */
export interface FileBlameStats {
  filePath: string;
  totalLines: number;
  aiLines: number;
  humanLines: number;
  mixedLines: number;
  unknownLines: number;
  aiPercentage: number;
  humanPercentage: number;
  models: Record<string, number>;
}

/**
 * Parse a stored trace record JSON string.
 */
function _parseRecord(json: string): AgentTraceRecord | null {
  try {
    return JSON.parse(json) as AgentTraceRecord;
  } catch {
    return null;
  }
}

/**
 * Get blame data for every line of a file by scanning agent traces
 * that reference the given file path.
 *
 * Lines not covered by any trace range default to 'unknown'.
 */
export async function getFileBlame(filePath: string, totalLines: number): Promise<BlameLineInfo[]> {
  // Initialize all lines as unknown
  const lines: BlameLineInfo[] = Array.from({ length: totalLines }, (_, i) => ({
    lineNumber: i + 1,
    attribution: 'unknown' as ContributorType,
    confidence: 0,
  }));

  // Query all traces that reference this file
  const dbTraces = await agentTraceRepository.findByFilePath(filePath);

  // Sort by timestamp ascending so later traces overwrite earlier ones
  dbTraces.sort((a, b) => {
    const ta = new Date(a.timestamp).getTime();
    const tb = new Date(b.timestamp).getTime();
    return ta - tb;
  });

  for (const record of dbTraces) {
    const meta = record.metadata as Record<string, unknown> | undefined;
    const sessionId = meta?.sessionId as string | undefined;
    const toolName = meta?.toolName as string | undefined;

    for (const file of record.files) {
      if (file.path !== filePath) continue;

      for (const conversation of file.conversations) {
        const contributorType = conversation.contributor?.type ?? 'unknown';
        const modelId = conversation.contributor?.model_id;
        const url = conversation.url;

        for (const range of conversation.ranges) {
          applyRangeToLines(lines, range, {
            attribution: contributorType,
            modelId: range.contributor?.model_id ?? modelId,
            toolName,
            sessionId,
            conversationUrl: url,
            timestamp: record.timestamp,
          });
        }
      }
    }
  }

  return lines;
}

/**
 * Get blame info for a single line of a file.
 */
export async function getLineBlame(
  filePath: string,
  lineNumber: number,
  totalLines: number
): Promise<BlameLineInfo> {
  const all = await getFileBlame(filePath, totalLines);
  return all[lineNumber - 1] ?? {
    lineNumber,
    attribution: 'unknown',
    confidence: 0,
  };
}

/**
 * Get aggregate blame statistics for a file.
 */
export async function getFileBlameStats(
  filePath: string,
  totalLines: number
): Promise<FileBlameStats> {
  const lines = await getFileBlame(filePath, totalLines);

  let aiLines = 0;
  let humanLines = 0;
  let mixedLines = 0;
  let unknownLines = 0;
  const models: Record<string, number> = {};

  for (const line of lines) {
    switch (line.attribution) {
      case 'ai':
        aiLines++;
        if (line.modelId) {
          models[line.modelId] = (models[line.modelId] || 0) + 1;
        }
        break;
      case 'human':
        humanLines++;
        break;
      case 'mixed':
        mixedLines++;
        break;
      default:
        unknownLines++;
    }
  }

  return {
    filePath,
    totalLines,
    aiLines,
    humanLines,
    mixedLines,
    unknownLines,
    aiPercentage: totalLines > 0 ? (aiLines / totalLines) * 100 : 0,
    humanPercentage: totalLines > 0 ? (humanLines / totalLines) * 100 : 0,
    models,
  };
}

/**
 * Get blame stats for multiple files at once.
 */
export async function getBulkFileBlameStats(
  files: { path: string; lineCount: number }[]
): Promise<FileBlameStats[]> {
  const results: FileBlameStats[] = [];
  for (const file of files) {
    results.push(await getFileBlameStats(file.path, file.lineCount));
  }
  return results;
}

// --- Internal helpers ---

interface BlameAttribution {
  attribution: ContributorType;
  modelId?: string;
  toolName?: string;
  sessionId?: string;
  conversationUrl?: string;
  timestamp?: string;
}

function applyRangeToLines(
  lines: BlameLineInfo[],
  range: TraceRange,
  info: BlameAttribution
): void {
  const start = Math.max(1, range.start_line);
  const end = Math.min(lines.length, range.end_line);

  for (let i = start; i <= end; i++) {
    const idx = i - 1;
    if (idx < 0 || idx >= lines.length) continue;

    // Content hash match gives higher confidence
    const confidence = range.content_hash ? 0.9 : 0.7;

    // Only overwrite if new attribution has equal or higher confidence
    if (confidence >= lines[idx].confidence) {
      lines[idx] = {
        lineNumber: i,
        attribution: info.attribution,
        modelId: info.modelId,
        toolName: info.toolName,
        sessionId: info.sessionId,
        conversationUrl: info.conversationUrl,
        timestamp: info.timestamp,
        confidence,
      };
    }
  }
}
